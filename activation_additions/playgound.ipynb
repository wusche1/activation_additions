{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Basic demonstration of sweeps and metrics operation.\"\"\"\n",
    "\n",
    "# %%\n",
    "# Imports, etc.\n",
    "\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torch\n",
    "\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from activation_additions import (\n",
    "    prompt_utils,\n",
    "    utils,\n",
    "    metrics,\n",
    "    hook_utils\n",
    ")\n",
    "from activation_additions.prompt_utils import (\n",
    "    ActivationAddition,\n",
    "    pad_tokens_to_match_activation_additions,\n",
    "    get_block_name,\n",
    ")\n",
    "utils.enable_ipython_reload()\n",
    "\n",
    "# Disable gradients to save memory during inference\n",
    "_ = torch.set_grad_enabled(False)\n",
    "\n",
    "from typing import List, Union,Dict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from activation_additions import (\n",
    "    prompt_utils,\n",
    "    hook_utils,\n",
    "    hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-xl into HookedTransformer\n",
      "Moving model to device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Load a model\n",
    "MODEL = HookedTransformer.from_pretrained(model_name=\"gpt2-xl\", device=\"cpu\")\n",
    "_ = MODEL.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.898438930511475"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_search.conditional_perplexity(MODEL,\n",
    "    MODEL.to_tokens(\"The only thing, that we need to fear is\"),\n",
    "    MODEL.to_tokens(\" fear itself\")[:,1:]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4616594463586807"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity=hyperparameter_search.conditional_perplexity(MODEL,\n",
    "    MODEL.to_tokens(\"The only thing we have to fear is\"),MODEL.to_tokens(\" fear itself\")[:, 1:])\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActAds =[prompt_utils.ActivationAddition(coeff=4, act_name=6,prompt=\" Pizza!\"),\n",
    "         prompt_utils.ActivationAddition(coeff=-4, act_name=6,prompt=\" fear\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([8.31489634513855], [5.5109670758247375])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_search.completion_perplexities(\n",
    "    MODEL,\n",
    "    [MODEL.to_tokens(\"The only thing we have to fear is\")],\n",
    "    [MODEL.to_tokens(\" fear itself\")[:, 1:]],\n",
    "    [MODEL.to_tokens(\" Pizza!\")[:, 1:]],\n",
    "    ActAds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=hyperparameter_search.layer_coefficient_gridsearch(\n",
    "    MODEL,\n",
    "    [\"The only thing we have to fear is\", \"I feel really\"],\n",
    "    {\" Pizza!\":1,\" fear\":-1},\n",
    "    [1,2,3,4],\n",
    "    [3,6,9,12],\n",
    "    [\" fear itself\", \" afraid\"],\n",
    "    [\" Pizza!\", \" hungry\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Perplexity (wanted)</th>\n",
       "      <th>Perplexity (unwanted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.265073</td>\n",
       "      <td>7.755989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13.439856</td>\n",
       "      <td>10.905490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13.199443</td>\n",
       "      <td>8.092573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12.226157</td>\n",
       "      <td>10.160707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14.167190</td>\n",
       "      <td>8.620543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10.603421</td>\n",
       "      <td>9.711972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13.835853</td>\n",
       "      <td>9.299639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10.121796</td>\n",
       "      <td>9.510039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9.697480</td>\n",
       "      <td>7.860976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14.010214</td>\n",
       "      <td>11.077999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>16.109994</td>\n",
       "      <td>8.918986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12.322976</td>\n",
       "      <td>9.866724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15.360357</td>\n",
       "      <td>9.690388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10.783916</td>\n",
       "      <td>8.730551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>15.007424</td>\n",
       "      <td>10.072684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>10.109302</td>\n",
       "      <td>8.608566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8.726061</td>\n",
       "      <td>7.644121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14.111527</td>\n",
       "      <td>11.123536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>15.532867</td>\n",
       "      <td>8.316993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12.514631</td>\n",
       "      <td>9.823189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>14.605862</td>\n",
       "      <td>8.553080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11.245539</td>\n",
       "      <td>9.172715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>14.240752</td>\n",
       "      <td>8.634448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>10.770484</td>\n",
       "      <td>9.041758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13.655914</td>\n",
       "      <td>8.007947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13.651155</td>\n",
       "      <td>10.973539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>15.351886</td>\n",
       "      <td>8.837275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>12.050155</td>\n",
       "      <td>9.653095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>14.552065</td>\n",
       "      <td>9.550159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11.352235</td>\n",
       "      <td>9.382363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13.875143</td>\n",
       "      <td>9.729464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>11.277143</td>\n",
       "      <td>9.396844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer  Coefficient  Perplexity (wanted)  Perplexity (unwanted)\n",
       "0       1            3             9.265073               7.755989\n",
       "1       1            3            13.439856              10.905490\n",
       "2       1            6            13.199443               8.092573\n",
       "3       1            6            12.226157              10.160707\n",
       "4       1            9            14.167190               8.620543\n",
       "5       1            9            10.603421               9.711972\n",
       "6       1           12            13.835853               9.299639\n",
       "7       1           12            10.121796               9.510039\n",
       "8       2            3             9.697480               7.860976\n",
       "9       2            3            14.010214              11.077999\n",
       "10      2            6            16.109994               8.918986\n",
       "11      2            6            12.322976               9.866724\n",
       "12      2            9            15.360357               9.690388\n",
       "13      2            9            10.783916               8.730551\n",
       "14      2           12            15.007424              10.072684\n",
       "15      2           12            10.109302               8.608566\n",
       "16      3            3             8.726061               7.644121\n",
       "17      3            3            14.111527              11.123536\n",
       "18      3            6            15.532867               8.316993\n",
       "19      3            6            12.514631               9.823189\n",
       "20      3            9            14.605862               8.553080\n",
       "21      3            9            11.245539               9.172715\n",
       "22      3           12            14.240752               8.634448\n",
       "23      3           12            10.770484               9.041758\n",
       "24      4            3            13.655914               8.007947\n",
       "25      4            3            13.651155              10.973539\n",
       "26      4            6            15.351886               8.837275\n",
       "27      4            6            12.050155               9.653095\n",
       "28      4            9            14.552065               9.550159\n",
       "29      4            9            11.352235               9.382363\n",
       "30      4           12            13.875143               9.729464\n",
       "31      4           12            11.277143               9.396844"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.remove_all_hook_fns()\n",
    "add_actads_to_model(MODEL,ActAds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActAds =[prompt_utils.ActivationAddition(coeff=4, act_name=6,prompt=\" hate\"),\n",
    "         prompt_utils.ActivationAddition(coeff=-4, act_name=6,prompt=\" love\")]\n",
    "hook_fns=hook_utils.hook_fns_from_activation_additions(MODEL, ActAds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for act_name in hook_fns.keys():\n",
    "    for hook_fn in hook_fns[act_name]:\n",
    "        MODEL.add_hook(act_name, hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_kwargs = {'temperature': 1, 'freq_penalty': 1, 'top_p': .3, 'model': MODEL}\n",
    "get_x_vector_preset = partial(prompt_utils.get_x_vector, pad_method=\"tokens_right\",\n",
    "                              model=MODEL,\n",
    "                              custom_pad_id=MODEL.to_single_token(\" \"))\n",
    "steering_vector=[*get_x_vector_preset(prompt1=\"hello\", prompt2=\"bye\", coeff=2, act_name=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_fns=hook_utils.hook_fns_from_activation_additions(MODEL, steering_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'activation_additions.hook_utils' has no attribute 'hook_fns_from_rich_prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hook_fns \u001b[39m=\u001b[39mhook_utils\u001b[39m.\u001b[39;49mhook_fns_from_rich_prompts(model\u001b[39m=\u001b[39mMODEL, rich_prompts\u001b[39m=\u001b[39msteering_vector)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'activation_additions.hook_utils' has no attribute 'hook_fns_from_rich_prompts'"
     ]
    }
   ],
   "source": [
    "#hook_fns =hook_utils.hook_fns_from_rich_prompts(model=MODEL, rich_prompts=steering_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "blocks.6.hook_resid_pre\n",
      "<class 'list'>\n",
      "<function hook_fn_from_activations.<locals>.prompt_hook at 0x7f433c5a4ca0>\n"
     ]
    }
   ],
   "source": [
    "for act_name, hook_fn in hook_fns.items():\n",
    "    print(type(act_name))\n",
    "    print(act_name)\n",
    "    print(type(hook_fn))\n",
    "    print(hook_fn[1])\n",
    "    #MODEL.add_hook(act_name, hook_fn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n",
      "<class 'function'>\n"
     ]
    }
   ],
   "source": [
    "name=\"blocks.2.hook_resid_pre\"\n",
    "for hook_fn in hook_fns[name]:\n",
    "    print(type(hook_fn))\n",
    "    MODEL.add_hook(name, hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=MODEL.to_tokens(\"Hello workd\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.remove_all_hook_fns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpt2_logits, gpt2_cache = MODEL.run_with_cache(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hook\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hook' is not defined"
     ]
    }
   ],
   "source": [
    "hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wuschel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
